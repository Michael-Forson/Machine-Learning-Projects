{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c42663-7185-4fae-aa61-1bf7d3b3ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6830cf-cb44-488f-822c-dc9bf8c14675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc427af-690d-41a1-81e0-b9a1a2ca04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f53ade-55a6-43f6-a9d2-aaa0b4ac26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=np.array(data)\n",
    "# m,n = data.shape\n",
    "# np.random.shuffle(data)\n",
    "# data_dev = data[0:1000]\n",
    "# Y_dev = data_dev[0].T\n",
    "# X_dev = data_dev[1:n]\n",
    "\n",
    "# data_train = data[1000:m].T\n",
    "# Y_train = data_train[0]\n",
    "# X_train = data_train[1:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75b4ea3-e356-4071-b906-2ec2d7f15877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_params():\n",
    "#     W1= np.random.randn(10,784)-0.5\n",
    "#     b1= np.random.randn(10,1)-0.5\n",
    "#     W2= np.random.randn(10,10)-0.5\n",
    "#     b2= np.random.randn(10,1)-0.5\n",
    "#     return W1,b1,W2,b2\n",
    "    \n",
    "# def ReLU(Z):\n",
    "#     return np.maximum(0,Z)\n",
    "    \n",
    "# def softmax(Z):\n",
    "#     A = np.exp(Z) / sum(np.exp(Z))\n",
    "#     return A\n",
    "    \n",
    "# def forward_prop(W1,b1,W2,b2,X):\n",
    "#     Z1=W1.dot(X)\n",
    "#     A1=ReLU(Z1)\n",
    "#     Z2 = W2.dot(A1) + b2\n",
    "#     A2 = softmax(A1)\n",
    "#     return Z1,A1,Z2,A2\n",
    "    \n",
    "# def one_hot(Y):\n",
    "#     one_hot_Y = np.zeros(Y.size,Y.max() +1)\n",
    "#     one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "#     one_hot_Y = one_hot_Y.T\n",
    "#     return one_hot_Y\n",
    "    \n",
    "# def deriv_ReLU(Z):\n",
    "#     return Z>0\n",
    "    \n",
    "# def back_prop(Z1,A1,Z2,A2):\n",
    "#     one_hot_Y=one_hot(y)\n",
    "#     dZ2=A2-one_hot_Y\n",
    "#     dW2 = 1/m * dZ2.dot(A1.T)\n",
    "#     db2 = 1/m * np.sum(dZ2, 2)\n",
    "#     dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n",
    "#     dW1 = 1/m * dZ1.dot(X.T)\n",
    "#     db1 = 1/m * np.sum(dz1,2)\n",
    "#     return dW1,db1,dW2,db2\n",
    "\n",
    "# def update_params(W1,b1,W2,b2,dW1,db1,dW2,db2,alpha):\n",
    "#     W1=W1-aplha*dW1\n",
    "#     b1=b1-alpha*db1\n",
    "#     W2=W2-alpha*dW2\n",
    "#     b2=b2-aplha*db2\n",
    "#     return W1,b1,W2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5093839b-28e7-4bfa-858e-aa107916db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predictions(A2):\n",
    "#     return np.argmax(A2,0)\n",
    "    \n",
    "# def get_accuracy(predictions,Y):\n",
    "#     print(predictions,Y)\n",
    "#     return np.sum(predictions == Y)/Y.size\n",
    "    \n",
    "# def gradient_descent(X,Y,iterations,aplha):\n",
    "#     W1,b1,W2,b2= init_params()\n",
    "#     for i in range(iterations):\n",
    "#         Z1,A1,Z2,A2 = forward_prop(W1,b1,W2,b2,X)\n",
    "#         dW1, db1,dW2,db2 = back_prop(Z1,A1,Z2,A2,W2,X,Y)\n",
    "#         W1, b1,W2, b2= update_params(W1,b1,W2,b2,dW1,db1,dW1,db1,dW2,db2,alpha)\n",
    "#         if i % 50==0:\n",
    "#             print(\"Iterations:\",i)\n",
    "#             print(\"Accuracy: \" ,get_accuracy(get_predictions(A2,Y)))\n",
    "#     return W1,b1,W2,b2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d7f559-609a-4579-aeac-ed0d9ee42da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67b107-2ded-4988-a3d8-911ff9b37481",
   "metadata": {},
   "source": [
    "# Plan\n",
    "1. Implementation layer\n",
    "2. create the base layer\n",
    "3. Create  Dense Layer\n",
    "4.  Create Activation Layer\n",
    "5. Implment activation functions and loss functions\n",
    "6. Solve XOR (MNIST in descriptions)\n",
    "\n",
    "### Machine Learning Steps\n",
    "1.  Feed input. Data flows from layer to layer. Retrieve output\n",
    "    > y = network(x,w)\n",
    "2. calculate the error\n",
    "    > e.g E = 1/2(y'-y)2\n",
    "3. Adjust the parameters using gradient descent\n",
    "    > w<- w=a*(dE)/(dw)\n",
    "4. start again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82450e95-a8f4-414c-bf55-a4c73e9ac567",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
